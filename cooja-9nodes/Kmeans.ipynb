{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#\"Decomment for install\"\n",
    "#!pip install kmeans\n",
    "#!pip install seaborn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Modules to install via pip pandas,ipynb\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import json\n",
    "from pprint import pprint\n",
    "import os\n",
    "import import_ipynb\n",
    "import sys\n",
    "import kmeans\n",
    "sys.path.append('../')\n",
    "from functions import *\n",
    "from pandas.plotting import scatter_matrix\n",
    "import cmath as math\n",
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "from sklearn import cluster\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics.cluster import normalized_mutual_info_score\n",
    "from sklearn.metrics.cluster import adjusted_rand_score\n",
    "from sklearn.cluster import KMeans\n",
    "# scipy\n",
    "from scipy.cluster.vq import kmeans,vq,whiten\n",
    "import sklearn.metrics as sm\n",
    "import seaborn as sns\n",
    "from sklearn.decomposition import PCA\n",
    "%matplotlib inline\n",
    "import random\n",
    "random.seed(6666)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Importing test_1BH_2018-11-09_12_31_25.json\n",
      "Importing test_1BH_2018-11-09_14_37_46.json\n",
      "Importing test_nom_2018-11-09_08_55_11.json\n",
      "[0 0 0 0 2 0 0 0 0 0 0 0 0 2 0 0 0 0 1 1 1 1 1 1 1 1 1]\n",
      "     pkt     rtt   ttl\n",
      "0    0.0  1342.0  63.0\n",
      "1    1.0  8170.0  63.0\n",
      "2    2.0   973.0  63.0\n",
      "3    3.0   848.0  63.0\n",
      "4    4.0  1022.0  63.0\n",
      "5    5.0  2406.0  63.0\n",
      "6    6.0   849.0  63.0\n",
      "7    7.0  3766.0  63.0\n",
      "8    8.0  1406.0  63.0\n",
      "9    9.0   824.0  63.0\n",
      "10  10.0   862.0  63.0\n",
      "11  11.0  3338.0  63.0\n",
      "12  12.0  2104.0  63.0\n",
      "13  13.0  1001.0  63.0\n",
      "14  14.0  2940.0  63.0\n",
      "15  15.0   904.0  63.0\n",
      "16  16.0   976.0  63.0\n",
      "17  17.0  1321.0  63.0\n",
      "18  18.0  1484.0  63.0\n",
      "19  19.0  1790.0  63.0\n",
      "20  20.0  1300.0  63.0\n",
      "21  21.0  1213.0  63.0\n",
      "22  22.0   746.0  63.0\n",
      "23  23.0   818.0  63.0\n",
      "24  24.0  2494.0  63.0\n",
      "25  25.0   709.0  63.0\n",
      "26  26.0  1031.0  63.0\n",
      "27  27.0  1623.0  63.0\n",
      "28  28.0  1018.0  63.0\n",
      "29  29.0  1406.0  63.0\n",
      "..   ...     ...   ...\n",
      "68  70.0  1403.0  63.0\n",
      "69  71.0  1052.0  63.0\n",
      "70  72.0  1362.0  63.0\n",
      "71  73.0  3128.0  63.0\n",
      "72  74.0  1390.0  63.0\n",
      "73  75.0  1309.0  63.0\n",
      "74  76.0  2055.0  63.0\n",
      "75  77.0  1664.0  63.0\n",
      "76  78.0  1884.0  63.0\n",
      "77  79.0  1697.0  63.0\n",
      "78  80.0  1348.0  63.0\n",
      "79  81.0  1572.0  63.0\n",
      "80  82.0  1288.0  63.0\n",
      "81  83.0  1140.0  63.0\n",
      "82  84.0   498.0  63.0\n",
      "83  85.0  1016.0  63.0\n",
      "84  86.0  1849.0  63.0\n",
      "85  87.0  1220.0  63.0\n",
      "86  88.0  1883.0  63.0\n",
      "87  89.0  1718.0  63.0\n",
      "88  90.0  1365.0  63.0\n",
      "89  91.0  1495.0  63.0\n",
      "90  92.0  1790.0  63.0\n",
      "91  93.0  1229.0  63.0\n",
      "92  94.0  1348.0  63.0\n",
      "93  95.0  2054.0  63.0\n",
      "94  96.0  1689.0  63.0\n",
      "95  97.0   825.0  63.0\n",
      "96  98.0  3430.0  63.0\n",
      "97  99.0  1050.0  63.0\n",
      "\n",
      "[98 rows x 3 columns]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "dataList=coojaJsonImporter(\"./traces\")\n",
    "data=[]\n",
    "cases=[\n",
    "      \"BH1\",\n",
    "        \"BH2\",\n",
    "    \"normal\"\n",
    "      ]\n",
    "\n",
    "BlackHole=[-1,4,5+8]\n",
    "for nodeList in dataList:\n",
    "    data.append(createNodes(nodeList))\n",
    "\n",
    "#All data collection is in variable node that is a list of list of nodes\n",
    "#3 nets input x 9 nodes by net\n",
    "data[0][0].pkts[1:5] \n",
    "columns=[\n",
    "    \"count\",\n",
    "    \"label\"\n",
    "]\n",
    "d={ \"label\":[],\n",
    "    \"count\":[],\n",
    "    \"std\":  [],\n",
    "    \"mean\": [],\n",
    "    \"var\":  [],\n",
    "    \"25%\":  [],\n",
    "   \"50%\":[],\n",
    "   \"75%\":[],\n",
    "   \"min\":[],\n",
    "   \"max\":[],\n",
    "   \"hop\":[]\n",
    "   #\"rtt/pkt\":[]\n",
    "}\n",
    "count=[]\n",
    "labels=[]\n",
    "var=[]\n",
    "#stats=pd.DataFrame(columns=columns)\n",
    "rows=[count,labels]\n",
    "for i in range(len(data)):\n",
    "    for j in range(len(data[i])):\n",
    "            #df1 = df1.assign(e=p.Series(np.random.randn(sLength)).values)\n",
    "            node=data[i][j]\n",
    "            name=str(j)+\" \"+cases[i]\n",
    "            #print(name)\n",
    "            #print(node.pkts['pkt'].count())\n",
    "            #stats[\"count\"]=node.pkts['pkt'].count()\n",
    "            d[\"count\"].append(data[i][j].pkts['rtt'].count())\n",
    "            d[\"std\"].append(data[i][j].pkts['rtt'].std())\n",
    "            d[\"mean\"].append(data[i][j].pkts['rtt'].mean())\n",
    "            d[\"var\"].append(data[i][j].pkts['rtt'].var())\n",
    "            d[\"label\"].append(cases[i])\n",
    "            d[\"25%\"].append(data[i][j].pkts['rtt'].describe()[\"25%\"])\n",
    "            d[\"50%\"].append(data[i][j].pkts['rtt'].describe()[\"50%\"])\n",
    "            d[\"75%\"].append(data[i][j].pkts['rtt'].describe()[\"75%\"])\n",
    "            d[\"min\"].append(data[i][j].pkts['rtt'].describe()[\"min\"])\n",
    "            d[\"max\"].append(data[i][j].pkts['rtt'].describe()[\"max\"])\n",
    "            d[\"hop\"].append(float(data[i][j].hop))\n",
    "            ## d[\"max\"].append(data[i][j].pkts['rtt']\n",
    "            #var.append(data[i][j].pkts['pkt'].var())\n",
    "            #stats[name]\n",
    "            #stats= stats.assign(ip=pd.Series(node.pkts['pkt'].describe()).values)\n",
    "            #stats.append(node.pkts['pkt'].describe())\n",
    "\n",
    "            \n",
    "            \n",
    "stats=pd.DataFrame(d)            \n",
    "\n",
    "stats\n",
    "correction=[]\n",
    "correction2=[] #for 3 cluster 0:normal net 1:bh net 2:bh\n",
    "correction3=[] #for 3 cluster 0:normal net 1:bh net 2:bh net\n",
    "for i in range(len(d[\"label\"])):\n",
    "    el=d[\"label\"][i]\n",
    "    if el==\"normal\":\n",
    "        correction.append(1)\n",
    "        correction2.append(1)\n",
    "        \n",
    "    else:\n",
    "        #print(el==\"BH2\" and i==BlackHole[2])\n",
    "        correction.append(0)\n",
    "        if ((el==\"BH1\" and i==BlackHole[1]) or\n",
    "            (el==\"BH2\" and i==BlackHole[2])):\n",
    "            \n",
    "            correction2.append(2)\n",
    "        else:\n",
    "            correction2.append(0)\n",
    "        \n",
    "\n",
    "correction=np.array(correction)\n",
    "correction2=np.array(correction2)\n",
    "print(correction2)\n",
    "stats.head()\n",
    "#findMissingPackets(data[0][0])\n",
    "print(data[0][0].pktsC)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data=stats.drop([\"label\",\"25%\",\"std\",\"mean\",\"75%\",\"50%\",\"min\",\"max\"],axis=1)\n",
    "\n",
    "dataC=stats[\"label\"]\n",
    "print(data.head())\n",
    "#Y = data[['var']]\n",
    "#X = data[['std']]\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Kmeans with 2 clusters, using just count, mean and hop feature we can get 85% of understanding probability\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "kmeans = KMeans(n_clusters=2)\n",
    "kmeans.fit(data)\n",
    "labels = kmeans.predict(data)\n",
    "centroids = kmeans.cluster_centers_\n",
    "\n",
    "\n",
    "print(labels)\n",
    "print(correction)\n",
    "\n",
    "# Performance Metrics\n",
    "accuracy=sm.accuracy_score(correction, labels)\n",
    "\n",
    "# Confusion Matrix\n",
    "confusionMatrix=sm.confusion_matrix(correction, labels)\n",
    "\n",
    "print(accuracy)\n",
    "print(confusionMatrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataplus=stats.drop([\"label\"],axis=1)\n",
    "data=dataplus\n",
    "kmeans = KMeans(n_clusters=2)\n",
    "kmeans.fit(data)\n",
    "labels = kmeans.predict(data)\n",
    "centroids = kmeans.cluster_centers_\n",
    "\n",
    "\n",
    "print(labels)\n",
    "print(correction)\n",
    "\n",
    "# Performance Metrics\n",
    "accuracy=sm.accuracy_score(correction, labels)\n",
    "\n",
    "# Confusion Matrix\n",
    "confusionMatrix=sm.confusion_matrix(correction, labels)\n",
    "\n",
    "print(accuracy)\n",
    "print(confusionMatrix)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Y=data\n",
    "Nc = range(1, 20)\n",
    "\n",
    "kmeans = [KMeans(n_clusters=i) for i in Nc]\n",
    "\n",
    "kmeans\n",
    "\n",
    "score = [kmeans[i].fit(Y).score(Y) for i in range(len(kmeans))]\n",
    "\n",
    "score\n",
    "\n",
    "plt.plot(Nc,score)\n",
    "\n",
    "plt.xlabel('Number of Clusters')\n",
    "\n",
    "plt.ylabel('Score')\n",
    "\n",
    "plt.title('Elbow Curve')\n",
    "\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(5, 5))\n",
    "\n",
    "colors = map(lambda x: colmap[x+1], labels)\n",
    "\n",
    "\n",
    "plt.scatter(data['count'], data['var'], alpha=0.5)\n",
    "plt.scatter(centroids[:, 0], centroids[:, 1], c='red', s=50)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#https://www.learndatasci.com/tutorials/k-means-clustering-algorithms-python-intro/\n",
    "#df=np.array(X,Y)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "X = dataplus.iloc[:,0:4]\n",
    "pca = PCA(n_components=2)\n",
    "pca.fit(X)\n",
    "X_ = pca.transform(X)\n",
    "\n",
    "dfPCA = pd.DataFrame({'x1': X_[:,0], 'x2': X_[:,1]})\n",
    "dfPCA['labels'] = stats['label']\n",
    "dfPCA.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "labels = stats['label'].unique().tolist()\n",
    "plt.figure(figsize=(7,5))\n",
    "for lab in labels:\n",
    "    plt.scatter(dfPCA.loc[dfPCA['labels'] == lab, 'x1'],  dfPCA.loc[dfPCA['labels'] == lab, 'x2'], label=lab)\n",
    "    plt.legend()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Experiment with 3 clusters trying also to find the black Hole node, 0.74% of probability finding a black hole in the network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "kmeans = KMeans(n_clusters=3)\n",
    "kmeans.fit(dataplus)\n",
    "labels = kmeans.predict(dataplus)\n",
    "centroids = kmeans.cluster_centers_\n",
    "\n",
    "\n",
    "print(labels)\n",
    "print(correction2)\n",
    "\n",
    "\n",
    "# Performance Metrics\n",
    "accuracy=sm.accuracy_score(correction2, labels)\n",
    "\n",
    "# Confusion Matrix\n",
    "confusionMatrix=sm.confusion_matrix(correction2, labels)\n",
    "\n",
    "print(accuracy)\n",
    "print(confusionMatrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(len(labels)):\n",
    "    if labels[i]==2:\n",
    "        labels[i]=0\n",
    "       \n",
    "    if correction2[i]==2:\n",
    "        correction2[i]=0\n",
    "print(labels)\n",
    "print(correction2)        \n",
    "# Performance Metrics\n",
    "accuracy=sm.accuracy_score(correction2, labels)\n",
    "\n",
    "# Confusion Matrix\n",
    "confusionMatrix=sm.confusion_matrix(correction2, labels)\n",
    "\n",
    "print(accuracy)\n",
    "print(confusionMatrix)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Example adding also the 16 nodes, clearly the accuracy goes down as we dont have many data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataList=coojaJsonImporter(\"../cooja-16nodes/traces/\")\n",
    "\n",
    "data=[]\n",
    "cases=[\n",
    "      \"BH1\",\n",
    "        \"BH2\",\n",
    "    \"normal\",\n",
    "    \"BH3\"\n",
    "      ]\n",
    "\n",
    "BlackHole=[-1,4,5+8,-1]\n",
    "for nodeList in dataList:\n",
    "    data.append(createNodes(nodeList))\n",
    "dataList=coojaJsonImporter(\"../cooja-9nodes/traces/\")\n",
    "for nodeList in dataList:\n",
    "    data.append(createNodes(nodeList))\n",
    "    \n",
    "d={ \"label\":[],\n",
    "    \"count\":[],\n",
    "    \"std\":  [],\n",
    "    \"mean\": [],\n",
    "    \"var\":  [],\n",
    "    \"25%\":  [],\n",
    "   \"50%\":[],\n",
    "   \"75%\":[],\n",
    "   \"min\":[],\n",
    "   \"max\":[]\n",
    "   #\"rtt/pkt\":[]\n",
    "}\n",
    "count=[]\n",
    "labels=[]\n",
    "var=[]\n",
    "#stats=pd.DataFrame(columns=columns)\n",
    "rows=[count,labels]\n",
    "for i in range(len(data)):\n",
    "    for j in range(len(data[i])):\n",
    "            #df1 = df1.assign(e=p.Series(np.random.randn(sLength)).values)\n",
    "            node=data[i][j]\n",
    "            name=str(j)+\" \"+cases[i]\n",
    "            d[\"count\"].append(data[i][j].pkts['rtt'].count())\n",
    "            d[\"std\"].append(data[i][j].pkts['rtt'].std())\n",
    "            d[\"mean\"].append(data[i][j].pkts['rtt'].mean())\n",
    "            d[\"var\"].append(data[i][j].pkts['rtt'].var())\n",
    "            d[\"label\"].append(cases[i])\n",
    "            d[\"25%\"].append(data[i][j].pkts['rtt'].describe()[\"25%\"])\n",
    "            d[\"50%\"].append(data[i][j].pkts['rtt'].describe()[\"50%\"])\n",
    "            d[\"75%\"].append(data[i][j].pkts['rtt'].describe()[\"75%\"])\n",
    "            d[\"min\"].append(data[i][j].pkts['rtt'].describe()[\"min\"])\n",
    "            d[\"max\"].append(data[i][j].pkts['rtt'].describe()[\"max\"])\n",
    "          \n",
    "            \n",
    "            \n",
    "stats=pd.DataFrame(d)        \n",
    "correction=[]\n",
    "correction2=[] #for 3 cluster 0:normal net 1:bh net 2:bh\n",
    "for i in range(len(d[\"label\"])):\n",
    "    el=d[\"label\"][i]\n",
    "    if el==\"normal\":\n",
    "        correction.append(1)\n",
    "        correction2.append(1)\n",
    "        \n",
    "    else:\n",
    "        #print(el==\"BH2\" and i==BlackHole[2])\n",
    "        correction.append(0)\n",
    "        if ((el==\"BH1\" and i==BlackHole[1]) or\n",
    "            (el==\"BH2\" and i==BlackHole[2])):\n",
    "            \n",
    "            correction2.append(2)\n",
    "        else:\n",
    "            correction2.append(0)\n",
    "        \n",
    "\n",
    "correction=np.array(correction)\n",
    "correction2=np.array(correction2)\n",
    "data=stats.drop([\"label\",\"25%\",\"var\",\"75%\",\"50%\",\"min\",\"max\",\"mean\"],axis=1)\n",
    "\n",
    "kmeans = KMeans(n_clusters=2)\n",
    "kmeans.fit(data)\n",
    "labels = kmeans.predict(data)\n",
    "centroids = kmeans.cluster_centers_\n",
    "\n",
    "\n",
    "print(labels)\n",
    "print(correction)\n",
    "\n",
    "# Performance Metrics\n",
    "accuracy=sm.accuracy_score(correction, labels)\n",
    "\n",
    "# Confusion Matrix\n",
    "confusionMatrix=sm.confusion_matrix(correction, labels)\n",
    "\n",
    "print(accuracy)\n",
    "print(confusionMatrix)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#Last experiment\n",
    "\n",
    "using windows so we can have virtually more data to work\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "dataList=coojaJsonImporter(\"./traces\")\n",
    "data=[]\n",
    "cases=[\n",
    "      \"BH1\",\n",
    "        \"BH2\",\n",
    "    \"normal\"\n",
    "      ]\n",
    "\n",
    "for nodeList in dataList:\n",
    "    data.append(createNodes(nodeList))\n",
    "    \n",
    "d={ \"label\":[],\n",
    "    \"count\":[],\n",
    "    \"std\":  [],\n",
    "    \"mean\": [],\n",
    "    \"var\":  [],\n",
    "    \"25%\":  [],\n",
    "    \"50%\":[],\n",
    "   \"75%\":[],\n",
    "   \"min\":[],\n",
    "   \"max\":[],\n",
    "   \"hop\":[],\n",
    "   \"missing packets\":[]\n",
    "   #\"rtt/pkt\":[]\n",
    "}\n",
    "\n",
    "window=25\n",
    "for i in range(len(data)):\n",
    "    for j in range(len(data[i])):\n",
    "        n=len(data[i][j].pkts[\"rtt\"])\n",
    "        #print(n)\n",
    "        for z in range(0,n,window):\n",
    "            #print(z)\n",
    "            \n",
    "            #df1 = df1.assign(e=p.Series(np.random.randn(sLength)).values)\n",
    "            node=data[i][j]\n",
    "            name=str(j)+\" \"+cases[i]\n",
    "            d[\"count\"].append(data[i][j].pkts['rtt'][z:z+window].count())\n",
    "            d[\"std\"].append(data[i][j].pkts['rtt'][z:z+window].std())\n",
    "            d[\"mean\"].append(data[i][j].pkts['rtt'][z:z+window].mean())\n",
    "            d[\"var\"].append(data[i][j].pkts['rtt'][z:z+window].var())\n",
    "            d[\"label\"].append(cases[i])\n",
    "            d[\"25%\"].append(data[i][j].pkts['rtt'][z:z+window].describe()[\"25%\"])\n",
    "            d[\"50%\"].append(data[i][j].pkts['rtt'][z:z+window].describe()[\"50%\"])\n",
    "            d[\"75%\"].append(data[i][j].pkts['rtt'][z:z+window].describe()[\"75%\"])\n",
    "            d[\"min\"].append(data[i][j].pkts['rtt'][z:z+window].describe()[\"min\"])\n",
    "            d[\"max\"].append(data[i][j].pkts['rtt'][z:z+window].describe()[\"max\"])\n",
    "            d[\"hop\"].append(data[i][j].hop)\n",
    "            missingPackets=data[i][j].pkts['rtt'][z:z+window]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(len(data)):\n",
    "    for j in range(len(data[i])):\n",
    "        n=len(data[i][j].pkts[\"rtt\"])\n",
    "        #print(n)\n",
    "\n",
    "        \n",
    "#print(data[0][0].pkts[\"pkt\"])        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stats=pd.DataFrame(d)            \n",
    "print(stats.shape)\n",
    "stats=stats.dropna()\n",
    "print(stats.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "data=stats.drop([\"label\",\"25%\",\"count\",\"75%\",\"50%\",\"min\",\"max\",\"mean\"],axis=1)\n",
    "\n",
    "#dataplus=stats.drop([\"label\"],axis=1)\n",
    "\n",
    "#data=dataplus\n",
    "kmeans = KMeans(n_clusters=2)\n",
    "kmeans.fit(data)\n",
    "labels = kmeans.predict(data)\n",
    "centroids = kmeans.cluster_centers_\n",
    "\n",
    "data.columns\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "correction=[]\n",
    "#stats=stats.dropna()\n",
    "\n",
    "col=np.array(stats[\"label\"])\n",
    "\n",
    "for i in range(len(col)):\n",
    "    el=col[i]\n",
    "    if el==\"normal\":\n",
    "        correction.append(1)\n",
    "      \n",
    "        \n",
    "    else:\n",
    "       \n",
    "        correction.append(0)\n",
    "        \n",
    "\n",
    "correction=np.array(correction)\n",
    "print(len(correction))\n",
    "print(len(labels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#print(labels)\n",
    "#print(correction)\n",
    "\n",
    "# Performance Metrics\n",
    "accuracy=sm.accuracy_score(correction, labels)\n",
    "\n",
    "# Confusion Matrix\n",
    "confusionMatrix=sm.confusion_matrix(correction, labels)\n",
    "\n",
    "print(correction)\n",
    "print(labels)\n",
    "print(accuracy)\n",
    "print(confusionMatrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = data.iloc[:,0:4]\n",
    "pca = PCA(n_components=2)\n",
    "pca.fit(X)\n",
    "X_ = pca.transform(X)\n",
    "\n",
    "dfPCA = pd.DataFrame({'x1': X_[:,0], 'x2': X_[:,1]})\n",
    "dfPCA['labels'] = stats['label']\n",
    "dfPCA.head()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = stats['label'].unique().tolist()\n",
    "plt.figure(figsize=(7,5))\n",
    "for lab in labels:\n",
    "    plt.scatter(dfPCA.loc[dfPCA['labels'] == lab, 'x1'],  dfPCA.loc[dfPCA['labels'] == lab, 'x2'], label=lab, alpha=0.5)\n",
    "    plt.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "def findMissingPackets(node):\n",
    "    #print(node.pkts[\"pkt\"])\n",
    "    maxP=-1\n",
    "    \n",
    "    for el in node.pkts[\"pkt\"]:\n",
    "        if(el>maxP): maxP=int(el)\n",
    "    #print(maxP)\n",
    "    pkt=[None]*(maxP+1)\n",
    "    for i in range(len(node.pkts[\"pkt\"])):\n",
    "        index=int(node.pkts[\"pkt\"][i])\n",
    "        #print(index)\n",
    "        pkt[index]=node.pkts[\"rtt\"][i]\n",
    "        #pkt[)]=node.pkts[\"pkt\"][i]\n",
    "    return pkt\n",
    "      "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(type(node.pkts[\"pkt\"]))\n",
    "findMissingPackets(data[0][5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'na' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-5-d50d43ef884d>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mna\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'na' is not defined"
     ]
    }
   ],
   "source": [
    "print(type(pfna))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!/usr/bin/env python\n",
    "# coding: utf-8\n",
    "\n",
    "# Parsing json data \n",
    "# CoojaJsonImporter(dir) imports jsons from the dir in a list\n",
    "# dict2df(dict) imports one json and return a df \n",
    "# dict2df_list(dict) import one json and return a list of df\n",
    "\n",
    "# In[9]:\n",
    "\n",
    "\n",
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import json\n",
    "\n",
    "#Object idea= List of nodes\n",
    "#Node has (ip,hop,min_rtt,max_rtt,pkts,responses)\n",
    "#pkt is a dataframe with packets\n",
    "#hop is from 64-ttl\n",
    "\n",
    "\n",
    "class node(object):\n",
    "    ip = \"\"\n",
    "    hop= 0\n",
    "    min_rtt= 0\n",
    "    max_rtt= 0\n",
    "    pkts=pd.DataFrame()\n",
    "    pktsC=pd.DataFrame()\n",
    "    responses=0\n",
    "    \n",
    "    \n",
    "    # The class \"constructor\" - It's actually an initializer \n",
    "    def __init__(self,ip,hop,min_rtt,max_rtt,pkts,responses,pktsC):\n",
    "        self.ip = ip\n",
    "        self.hop=hop\n",
    "        self.min_rtt=min_rtt\n",
    "        self.max_rtt=max_rtt\n",
    "        self.pkts=pkts\n",
    "        self.responses=responses\n",
    "        self.pktsC=pktsC\n",
    "\n",
    "    def make_node(ip,hop,min_rtt,max_rtt,pkts,responses,pktsC):\n",
    "        node= node(ip,hop,min_rtt,max_rtt,pkts,responses,pktsC)\n",
    "        return node\n",
    "    \n",
    "    \n",
    "class packet(object):\n",
    "    rtt=np.NaN\n",
    "    pkt=np.NaN\n",
    "    ttl=np.NaN   \n",
    "    def __init__(self,rtt,pkt,ttl):\n",
    "        self.rtt=rtt\n",
    "        self.pkt=pkt\n",
    "        self.ttl=ttl\n",
    "    \n",
    "    \n",
    "    def make_packet(rtt,pkt,ttl):\n",
    "        package=package(rtt,pkt,ttl)\n",
    "\n",
    "def coojaJsonImporter(dir):\n",
    "        \n",
    "        dataList=[]\n",
    "\n",
    "        for file in os.listdir(dir):\n",
    "            print(\"Importing \"+ file)\n",
    "            with open(dir+\"/\" + file, 'r') as f:\n",
    "\n",
    "                dataList.append(json.load(f))\n",
    "\n",
    "        return dataList\n",
    "\n",
    "def dict2df(dict):\n",
    "    dfList=[]\n",
    "    bigdata=pd.DataFrame()\n",
    "    for key in dict.keys():\n",
    "        df=pd.DataFrame(dict[key]['pkts'])\n",
    "        df['ip']=key\n",
    "        \n",
    "        #dfList.append(df)\n",
    "        #print(df)\n",
    "        bigdata=bigdata.append(df,ignore_index=True)\n",
    "\n",
    "    return bigdata\n",
    "        \n",
    "def dict2df_list(dict):\n",
    "    dfList=[]\n",
    "    #dfList(pd.DataFrame(dict))\n",
    "    for key in dict.keys():\n",
    "        df=pd.DataFrame(dict[key]['pkts'])\n",
    "        df['ip']=key\n",
    "        df['hop']=64-(df['ttl'])\n",
    "        dfList.append(df)\n",
    "        #print(df)\n",
    "    return dfList\n",
    "\n",
    "\n",
    "###Function to create nodes, create a list of nodes\n",
    "### \n",
    "    \n",
    "def createNodes(dict):\n",
    "    nodeList=[]\n",
    "    #dfList(pd.DataFrame(dict))\n",
    "    for ip in dict.keys():\n",
    "        pkts=pd.DataFrame(dict[ip]['pkts'])\n",
    "        #(ip,hop,min_rtt,max_rtt,pkts,responses)\n",
    "        #print(dict.get(ip).get(\"max_rtt\"))\n",
    "        #findMissingPackets(dict.get(ip))\n",
    "        pkts1=dict.get(ip).get(\"pkts\")\n",
    "        pktsList=[]\n",
    "        for p in pkts1:\n",
    "            #print(p.get(\"rtt\"))\n",
    "             #make_packet(rtt,pkt,ttl)\n",
    "            rtt=p.get(\"rtt\")\n",
    "            pkt=p.get(\"pkt\")\n",
    "            ttl=p.get(\"ttl\")\n",
    "            pack=packet(rtt,pkt,ttl)\n",
    "            pktsList.append(pack)\n",
    "        min_rtt=dict.get(ip).get(\"min_rtt\")\n",
    "        max_rtt=dict.get(ip).get(\"max_rtt\")\n",
    "        responses=dict.get(ip).get(\"responses\")\n",
    "        hop=64-(int(pkts[0:1][\"ttl\"]))\n",
    "        #print(type(pkts[0:1][\"ttl\"]))\n",
    "        #print(pkts[0:1][\"ttl\"])\n",
    "        n=node(ip,hop,min_rtt,max_rtt,pkts,responses,pkts)\n",
    "        \n",
    "        nodeList.append(n)\n",
    "        #print(type(nodeList[0].pkts[0]))\n",
    "        \n",
    "    return nodeList"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Importing test_1BH_2018-11-09_12_31_25.json\n",
      "Importing test_1BH_2018-11-09_14_37_46.json\n",
      "Importing test_nom_2018-11-09_08_55_11.json\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[{'rtt': 862.0, 'pkt': 0.0, 'ttl': 63.0},\n",
       " {'rtt': 1188.0, 'pkt': 1.0, 'ttl': 63.0},\n",
       " {'rtt': 1333.0, 'pkt': 2.0, 'ttl': 63.0},\n",
       " {'rtt': 913.0, 'pkt': 3.0, 'ttl': 63.0},\n",
       " {'rtt': 1032.0, 'pkt': 4.0, 'ttl': 63.0},\n",
       " {'rtt': 1534.0, 'pkt': 5.0, 'ttl': 63.0},\n",
       " {'rtt': 1409.0, 'pkt': 6.0, 'ttl': 63.0},\n",
       " {'rtt': 1112.0, 'pkt': 7.0, 'ttl': 63.0},\n",
       " {'rtt': 1743.0, 'pkt': 8.0, 'ttl': 63.0},\n",
       " {'rtt': 2830.0, 'pkt': 9.0, 'ttl': 63.0},\n",
       " {'rtt': 865.0, 'pkt': 10.0, 'ttl': 63.0},\n",
       " {'rtt': 731.0, 'pkt': 11.0, 'ttl': 63.0},\n",
       " {'rtt': 712.0, 'pkt': 12.0, 'ttl': 63.0},\n",
       " {'rtt': 1483.0, 'pkt': 13.0, 'ttl': 63.0},\n",
       " {'rtt': 953.0, 'pkt': 14.0, 'ttl': 63.0},\n",
       " {'rtt': 1556.0, 'pkt': 15.0, 'ttl': 63.0},\n",
       " {'rtt': 1337.0, 'pkt': 16.0, 'ttl': 63.0},\n",
       " {'rtt': 1156.0, 'pkt': 17.0, 'ttl': 63.0},\n",
       " {'rtt': 968.0, 'pkt': 18.0, 'ttl': 63.0},\n",
       " {'rtt': 1217.0, 'pkt': 19.0, 'ttl': 63.0},\n",
       " {'rtt': 883.0, 'pkt': 20.0, 'ttl': 63.0},\n",
       " {'rtt': 1325.0, 'pkt': 21.0, 'ttl': 63.0},\n",
       " {'rtt': 1227.0, 'pkt': 22.0, 'ttl': 63.0},\n",
       " {'rtt': 933.0, 'pkt': 23.0, 'ttl': 63.0},\n",
       " {'rtt': 896.0, 'pkt': 24.0, 'ttl': 63.0},\n",
       " {'rtt': 1965.0, 'pkt': 25.0, 'ttl': 63.0},\n",
       " {'rtt': 1613.0, 'pkt': 26.0, 'ttl': 63.0},\n",
       " {'rtt': 1656.0, 'pkt': 27.0, 'ttl': 63.0},\n",
       " {'rtt': 1541.0, 'pkt': 28.0, 'ttl': 63.0},\n",
       " {'rtt': 1067.0, 'pkt': 29.0, 'ttl': 63.0},\n",
       " {'rtt': 1373.0, 'pkt': 30.0, 'ttl': 63.0},\n",
       " {'rtt': 917.0, 'pkt': 31.0, 'ttl': 63.0},\n",
       " {'rtt': 1056.0, 'pkt': 32.0, 'ttl': 63.0},\n",
       " {'rtt': 1040.0, 'pkt': 33.0, 'ttl': 63.0},\n",
       " {'rtt': 1041.0, 'pkt': 34.0, 'ttl': 63.0},\n",
       " {'rtt': 967.0, 'pkt': 35.0, 'ttl': 63.0},\n",
       " {'rtt': 920.0, 'pkt': 36.0, 'ttl': 63.0},\n",
       " {'rtt': 1018.0, 'pkt': 37.0, 'ttl': 63.0},\n",
       " {'rtt': 1357.0, 'pkt': 38.0, 'ttl': 63.0},\n",
       " {'rtt': 1122.0, 'pkt': 39.0, 'ttl': 63.0},\n",
       " {'rtt': 1452.0, 'pkt': 40.0, 'ttl': 63.0},\n",
       " {'rtt': 1061.0, 'pkt': 41.0, 'ttl': 63.0},\n",
       " {'rtt': 1322.0, 'pkt': 42.0, 'ttl': 63.0},\n",
       " {'rtt': 970.0, 'pkt': 43.0, 'ttl': 63.0},\n",
       " {'rtt': 975.0, 'pkt': 44.0, 'ttl': 63.0},\n",
       " {'rtt': 974.0, 'pkt': 45.0, 'ttl': 63.0},\n",
       " {'rtt': 1122.0, 'pkt': 46.0, 'ttl': 63.0},\n",
       " {'rtt': 912.0, 'pkt': 47.0, 'ttl': 63.0},\n",
       " {'rtt': 1704.0, 'pkt': 48.0, 'ttl': 63.0},\n",
       " {'rtt': 1068.0, 'pkt': 49.0, 'ttl': 63.0},\n",
       " {'rtt': 849.0, 'pkt': 50.0, 'ttl': 63.0},\n",
       " {'rtt': 1117.0, 'pkt': 51.0, 'ttl': 63.0},\n",
       " {'rtt': 1321.0, 'pkt': 52.0, 'ttl': 63.0},\n",
       " {'rtt': 1455.0, 'pkt': 53.0, 'ttl': 63.0},\n",
       " {'rtt': 1530.0, 'pkt': 54.0, 'ttl': 63.0},\n",
       " {'rtt': 1581.0, 'pkt': 55.0, 'ttl': 63.0},\n",
       " {'rtt': 939.0, 'pkt': 56.0, 'ttl': 63.0},\n",
       " {'rtt': 845.0, 'pkt': 57.0, 'ttl': 63.0},\n",
       " {'rtt': 1141.0, 'pkt': 58.0, 'ttl': 63.0},\n",
       " {'rtt': 1064.0, 'pkt': 59.0, 'ttl': 63.0},\n",
       " {'rtt': 936.0, 'pkt': 60.0, 'ttl': 63.0},\n",
       " {'rtt': 780.0, 'pkt': 61.0, 'ttl': 63.0},\n",
       " {'rtt': 943.0, 'pkt': 62.0, 'ttl': 63.0},\n",
       " {'rtt': 2786.0, 'pkt': 63.0, 'ttl': 63.0},\n",
       " {'rtt': 1111.0, 'pkt': 64.0, 'ttl': 63.0},\n",
       " {'rtt': 1072.0, 'pkt': 65.0, 'ttl': 63.0},\n",
       " {'rtt': 916.0, 'pkt': 66.0, 'ttl': 63.0},\n",
       " {'rtt': 1090.0, 'pkt': 67.0, 'ttl': 63.0},\n",
       " {'rtt': 1056.0, 'pkt': 68.0, 'ttl': 63.0},\n",
       " {'rtt': 1170.0, 'pkt': 69.0, 'ttl': 63.0},\n",
       " {'rtt': 975.0, 'pkt': 70.0, 'ttl': 63.0},\n",
       " {'rtt': 1052.0, 'pkt': 71.0, 'ttl': 63.0},\n",
       " {'rtt': 1084.0, 'pkt': 72.0, 'ttl': 63.0},\n",
       " {'rtt': 2059.0, 'pkt': 73.0, 'ttl': 63.0},\n",
       " {'rtt': 877.0, 'pkt': 74.0, 'ttl': 63.0},\n",
       " {'rtt': 882.0, 'pkt': 75.0, 'ttl': 63.0},\n",
       " {'rtt': 1055.0, 'pkt': 76.0, 'ttl': 63.0},\n",
       " {'rtt': 1240.0, 'pkt': 77.0, 'ttl': 63.0},\n",
       " {'rtt': 1066.0, 'pkt': 78.0, 'ttl': 63.0},\n",
       " {'rtt': 1440.0, 'pkt': 79.0, 'ttl': 63.0},\n",
       " {'rtt': 1876.0, 'pkt': 80.0, 'ttl': 63.0},\n",
       " {'rtt': 989.0, 'pkt': 81.0, 'ttl': 63.0},\n",
       " {'rtt': 1106.0, 'pkt': 82.0, 'ttl': 63.0},\n",
       " {'rtt': 824.0, 'pkt': 83.0, 'ttl': 63.0},\n",
       " {'rtt': 1168.0, 'pkt': 84.0, 'ttl': 63.0},\n",
       " {'rtt': 1102.0, 'pkt': 85.0, 'ttl': 63.0},\n",
       " {'rtt': 1162.0, 'pkt': 86.0, 'ttl': 63.0},\n",
       " {'rtt': 743.0, 'pkt': 87.0, 'ttl': 63.0},\n",
       " {'rtt': 1516.0, 'pkt': 88.0, 'ttl': 63.0},\n",
       " {'rtt': 1401.0, 'pkt': 89.0, 'ttl': 63.0},\n",
       " {'rtt': 1068.0, 'pkt': 90.0, 'ttl': 63.0},\n",
       " {'rtt': 1048.0, 'pkt': 91.0, 'ttl': 63.0},\n",
       " {'rtt': 957.0, 'pkt': 92.0, 'ttl': 63.0},\n",
       " {'rtt': 1619.0, 'pkt': 93.0, 'ttl': 63.0},\n",
       " {'rtt': 936.0, 'pkt': 94.0, 'ttl': 63.0},\n",
       " {'rtt': 800.0, 'pkt': 95.0, 'ttl': 63.0},\n",
       " {'rtt': 2062.0, 'pkt': 96.0, 'ttl': 63.0},\n",
       " {'rtt': 1558.0, 'pkt': 97.0, 'ttl': 63.0},\n",
       " {'rtt': 990.0, 'pkt': 98.0, 'ttl': 63.0},\n",
       " {'rtt': 902.0, 'pkt': 99.0, 'ttl': 63.0}]"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "dataList=coojaJsonImporter(\"./traces\")\n",
    "data=[]\n",
    "cases=[\n",
    "      \"BH1\",\n",
    "        \"BH2\",\n",
    "    \"normal\"\n",
    "      ]\n",
    "\n",
    "for nodeList in dataList:\n",
    "    data.append(createNodes(nodeList))\n",
    "    \n",
    "#print(data[0][5].responses)\n",
    "nodeList[\"aaaa::212:7404:4:404:\"]['pkts']"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
