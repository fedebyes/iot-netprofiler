{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Modules to install via pip pandas,ipynb\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import json\n",
    "from pprint import pprint\n",
    "import os\n",
    "import import_ipynb\n",
    "import sys\n",
    "import kmeans\n",
    "sys.path.append('../')\n",
    "from functions import *\n",
    "from trace_analysis import *\n",
    "from plots import *\n",
    "from trace_analysis_cooja2 import *\n",
    "from node import *\n",
    "from plots_analysis import *\n",
    "from pandas.plotting import scatter_matrix\n",
    "import cmath as math\n",
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "from sklearn import cluster\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics.cluster import normalized_mutual_info_score\n",
    "from sklearn.metrics.cluster import adjusted_rand_score\n",
    "from sklearn.cluster import KMeans\n",
    "# scipy\n",
    "from scipy.cluster.vq import kmeans,vq,whiten\n",
    "import sklearn.metrics as sm\n",
    "import seaborn as sns\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.decomposition import PCA\n",
    "%matplotlib inline\n",
    "import random\n",
    "random.seed(6666)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def analyze_network(directory,plots,pings,window):\n",
    "    cases=[]\n",
    "    casesAccuracy=[]\n",
    "    for row in plots:\n",
    "        cases.append(row[1])\n",
    "        casesAccuracy.append(row[2])\n",
    "        data=import_Cooja2(plots)\n",
    "    #pings=getPings(data)\n",
    "    #All data collection is in variable node that is a list of list of nodes\n",
    "    #3 nets input x 9 nodes by net\n",
    "    print(\"Processing...\")\n",
    "    d={ \"label\":[],\n",
    "       \"type\":[],\n",
    "        \"count\":[],\n",
    "        \"std\":  [],\n",
    "        \"mean\": [],\n",
    "        \"var\":  [],\n",
    "        \"hop\":[],\n",
    "\n",
    "       \"packet loss\":[],\n",
    "       \"outliers\":[],\n",
    "       \"node\":[]\n",
    "    }\n",
    "    #count=[]\n",
    "    labels=[]\n",
    "    var=[]\n",
    "    #window=100\n",
    "    #stats=pd.DataFrame(columns=columns)\n",
    "    n=pings\n",
    "\n",
    "    for i in range(len(data)):\n",
    "        #window=pings[i]\n",
    "\n",
    "        for j in range(len(data[i])):\n",
    "            #n=pings[i]\n",
    "\n",
    "            #print(n)\n",
    "            for z in range(0,n,int(window)):\n",
    "                #if(z+window>n):break\n",
    "                #print(z,z+window)\n",
    "\n",
    "                #df1 = df1.assign(e=p.Series(np.random.randn(sLength)).values)\n",
    "                node=data[i][j].pkts\n",
    "                name=str(j)+\" \"+cases[i]\n",
    "                nodeWindow=node[(node[\"seq\"]<z+window) & (node[\"seq\"]>=z)]\n",
    "                nodeWindowP=nodeWindow[\"rtt\"]\n",
    "                d[\"count\"].append(nodeWindowP.count())\n",
    "                #Case without outliers\n",
    "                #Case with outliers\n",
    "                std=0\n",
    "                if (nodeWindowP.std()>10):\n",
    "                    std=1\n",
    "                    std=nodeWindowP.std()\n",
    "\n",
    "                d[\"std\"].append(std)\n",
    "                mean=nodeWindowP.mean()\n",
    "                #if(mean<1):print(mean)\n",
    "                d[\"mean\"].append(mean)\n",
    "                var=0\n",
    "                if (nodeWindowP.var()>var): var=nodeWindowP.var()\n",
    "                d[\"var\"].append(var)\n",
    "                d[\"label\"].append(cases[i])\n",
    "                d[\"hop\"].append(data[i][j].hop)\n",
    "                d[\"type\"].append(casesAccuracy[i])\n",
    "                d[\"outliers\"].append(getOutliers(nodeWindow)[\"rtt\"].count())\n",
    "                missing=window-nodeWindow.count()\n",
    "                d[\"node\"].append(data[i][j].ip)\n",
    "                mP=getPercentageMissingPackets(nodeWindow,window)\n",
    "                PL=0\n",
    "                if(mP>30):\n",
    "                    PL=1\n",
    "                    PL=mP\n",
    "                d[\"packet loss\"].append(mP)\n",
    "\n",
    "\n",
    "\n",
    "    stats=pd.DataFrame(d)\n",
    "\n",
    "    dataK=stats.drop([\n",
    "        \"label\",\n",
    "        \"mean\",\n",
    "        \"var\",\n",
    "        \"std\",\n",
    "        #\"packet loss\",\n",
    "        \"outliers\",\n",
    "        \"hop\",\n",
    "        \"count\",\n",
    "        \"node\",\n",
    "        #\"type\"\n",
    "    ],axis=1)\n",
    "    dataK=dataK.fillna(0)\n",
    "\n",
    "    #print(dataK)\n",
    "    correction=[]\n",
    "    correction_alt=[]\n",
    "    col=np.array(dataK[\"type\"])\n",
    "    dataK=dataK.drop([\"type\"],axis=1)\n",
    "    #Creating simple array to correct unsupervised learning\n",
    "    #NB as it is unsupervised could happen that the correction are inverted\n",
    "    for i in range(len(col)):\n",
    "        el=d[\"type\"][i]\n",
    "        if el==\"normal\":\n",
    "            correction.append(1)\n",
    "            correction_alt.append(0)\n",
    "\n",
    "        else:\n",
    "\n",
    "            correction.append(0)\n",
    "            correction_alt.append(1)\n",
    "\n",
    "\n",
    "    dataC=stats[\"label\"]\n",
    "    kmeans = KMeans(n_clusters=2)\n",
    "    kmeans.fit(dataK)\n",
    "    labels = kmeans.predict(dataK)\n",
    "    centroids = kmeans.cluster_centers_\n",
    "    labels=accuracy_score_corrected(correction,labels)\n",
    "    predicted=[]\n",
    "    for i in range(len(labels)):\n",
    "\n",
    "        if(labels[i]==1):\n",
    "            predicted.append(\"normal\")\n",
    "        else: predicted.append(\"BH\")\n",
    "\n",
    "    #print(len(predicted))\n",
    "    stats[\"predicted\"]=pd.Series(np.array(predicted))\n",
    "    stats[\"predicted number\"]=pd.Series(np.array(labels))\n",
    "    stats[\"correction number\"]=pd.Series(np.array(correction))\n",
    "    stats_csv=stats[[\n",
    "        \"label\",\n",
    "        \"type\",\n",
    "        \"predicted\",\n",
    "        \"packet loss\",\n",
    "        \"outliers\",\n",
    "        \"std\",\n",
    "        \"hop\",\n",
    "        \"node\",\n",
    "        \"mean\"\n",
    "\n",
    "\n",
    "          ]]\n",
    "    stats_csv.to_csv(\"results_kmeans.csv\", sep='\\t', encoding='utf-8')\n",
    "    stats.head()\n",
    "    net_results={\n",
    "       \"case\":[],\n",
    "        \"predicted\":[],\n",
    "        \"real\":[]\n",
    "    }\n",
    "    #print(stats[\"predicted number\"])\n",
    "    for case in range(len(cases)):\n",
    "        subset=stats[stats[\"label\"]==cases[case]]\n",
    "        mean_predicted=str(subset[\"predicted number\"].mean()*100)+\"% normal\"\n",
    "        net_results[\"case\"].append(cases[case])\n",
    "        net_results[\"predicted\"].append(mean_predicted)\n",
    "        net_results[\"real\"].append(casesAccuracy[case])\n",
    "\n",
    "\n",
    "\n",
    "    results=pd.DataFrame(net_results)\n",
    "    results.to_csv(\"results_network_kmeans.csv\", sep='\\t', encoding='utf-8')\n",
    "    print(results)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing...\n",
      "        type  packet loss\n",
      "0         BH    91.666667\n",
      "1         BH   100.000000\n",
      "2         BH   100.000000\n",
      "3         BH   100.000000\n",
      "4         BH   100.000000\n",
      "5         BH   100.000000\n",
      "6         BH   100.000000\n",
      "7         BH   100.000000\n",
      "8         BH   100.000000\n",
      "9         BH   100.000000\n",
      "10        BH   100.000000\n",
      "11        BH   100.000000\n",
      "12        BH   100.000000\n",
      "13        BH   100.000000\n",
      "14        BH   100.000000\n",
      "15        BH   100.000000\n",
      "16        BH   100.000000\n",
      "17        BH    91.666667\n",
      "18        BH   100.000000\n",
      "19        BH   100.000000\n",
      "20        BH   100.000000\n",
      "21        BH   100.000000\n",
      "22        BH   100.000000\n",
      "23        BH   100.000000\n",
      "24        BH   100.000000\n",
      "25        BH   100.000000\n",
      "26        BH   100.000000\n",
      "27        BH   100.000000\n",
      "28        BH   100.000000\n",
      "29        BH   100.000000\n",
      "...      ...          ...\n",
      "1959  normal     0.000000\n",
      "1960  normal     0.000000\n",
      "1961  normal     0.000000\n",
      "1962  normal     0.000000\n",
      "1963  normal     0.000000\n",
      "1964  normal     0.000000\n",
      "1965  normal     0.000000\n",
      "1966  normal     0.000000\n",
      "1967  normal     0.000000\n",
      "1968  normal     8.333333\n",
      "1969  normal     0.000000\n",
      "1970  normal     0.000000\n",
      "1971  normal    25.000000\n",
      "1972  normal     8.333333\n",
      "1973  normal     0.000000\n",
      "1974  normal     0.000000\n",
      "1975  normal     0.000000\n",
      "1976  normal    16.666667\n",
      "1977  normal     0.000000\n",
      "1978  normal     0.000000\n",
      "1979  normal     0.000000\n",
      "1980  normal     0.000000\n",
      "1981  normal     0.000000\n",
      "1982  normal     8.333333\n",
      "1983  normal     0.000000\n",
      "1984  normal     0.000000\n",
      "1985  normal     0.000000\n",
      "1986  normal     0.000000\n",
      "1987  normal     0.000000\n",
      "1988  normal    33.333333\n",
      "\n",
      "[1989 rows x 2 columns]\n",
      "[0 0 0 ... 1 1 1]\n",
      "0.45701357466063347\n",
      "[0 0 0 ... 1 1 1]\n",
      "array([[ 484, 1046],\n",
      "       [  34,  425]])\n",
      "                              case                   predicted    real\n",
      "0    grid9_1bh-3_2019-02-13_16:28_  10.457516339869281% normal      BH\n",
      "1    grid9_1bh-3_2019-02-13_22:05_   11.11111111111111% normal      BH\n",
      "2    grid9_1bh-5_2019-02-13_15:31_   90.19607843137256% normal      BH\n",
      "3    grid9_1bh-5_2019-02-13_21:44_   90.19607843137256% normal      BH\n",
      "4    grid9_1bh-6_2019-02-13_12:59_    80.3921568627451% normal      BH\n",
      "5    grid9_1bh-6_2019-02-13_19:15_  62.091503267973856% normal      BH\n",
      "6    grid9_1bh-7_2019-02-13_15:08_   86.27450980392157% normal      BH\n",
      "7    grid9_1bh-7_2019-02-13_20:02_   75.81699346405229% normal      BH\n",
      "8    grid9_1bh-9_2019-02-13_15:57_   95.42483660130719% normal      BH\n",
      "9    grid9_1bh-9_2019-02-13_19:35_   81.69934640522875% normal      BH\n",
      "10  grid9_normal_2019-02-13_17:05_   81.69934640522875% normal  normal\n",
      "11  grid9_normal_2019-02-13_18:51_    98.0392156862745% normal  normal\n",
      "12  grid9_normal_2019-02-13_22:23_    98.0392156862745% normal  normal\n"
     ]
    }
   ],
   "source": [
    "#directory=os.getcwd()+\"/cooja3-9nodes/\"\n",
    "directory=\"../cooja3-9nodes/\"\n",
    "plots = [\n",
    "        #2 BH3\n",
    "        (directory+\"traces/1bh-3\", 'grid9_1bh-3_2019-02-13_16:28_',\"BH\"),\n",
    "        (directory+\"traces/1bh-3\", 'grid9_1bh-3_2019-02-13_22:05_',\"BH\"),\n",
    "        #2 BH5\n",
    "         (directory+\"traces/1bh-5\", 'grid9_1bh-5_2019-02-13_15:31_',\"BH\"),\n",
    "          (directory+\"traces/1bh-5\", 'grid9_1bh-5_2019-02-13_21:44_',\"BH\"),\n",
    "        #2 BH 6\n",
    "        (directory+\"traces/1bh-6\", 'grid9_1bh-6_2019-02-13_12:59_',\"BH\"),\n",
    "        (directory+\"traces/1bh-6\", 'grid9_1bh-6_2019-02-13_19:15_',\"BH\"),\n",
    "        #2 BH 7\n",
    "         (directory+\"traces/1bh-7\", 'grid9_1bh-7_2019-02-13_15:08_',\"BH\"),\n",
    "         (directory+\"traces/1bh-7\", 'grid9_1bh-7_2019-02-13_20:02_',\"BH\"),\n",
    "         #2 bh 9\n",
    "         (directory+\"traces/1bh-9\", 'grid9_1bh-9_2019-02-13_15:57_',\"BH\"),\n",
    "         (directory+\"traces/1bh-9\", 'grid9_1bh-9_2019-02-13_19:35_',\"BH\"),\n",
    "         #3 normal\n",
    "         (directory+\"traces/normal\", 'grid9_normal_2019-02-13_17:05_',\"normal\"),\n",
    "         (directory+\"traces/normal\",  \"grid9_normal_2019-02-13_18:51_\",\"normal\"),\n",
    "         (directory+\"traces/normal\",  \"grid9_normal_2019-02-13_22:23_\",\"normal\"),\n",
    "        ]\n",
    "\n",
    "analyze_network(directory,plots,200,12)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "directory=\"../cooja3-9nodes/\"\n",
    "plots = [\n",
    "        #2 BH3\n",
    "        ( \"traces/1bh-3\", 'grid9_1bh-3_2019-02-13_16:28_',\"BH\"),\n",
    "        ( \"traces/1bh-3\", 'grid9_1bh-3_2019-02-13_22:05_',\"BH\"),\n",
    "        #2 BH5\n",
    "         ( \"traces/1bh-5\", 'grid9_1bh-5_2019-02-13_15:31_',\"BH\"),\n",
    "          ( \"traces/1bh-5\", 'grid9_1bh-5_2019-02-13_21:44_',\"BH\"),\n",
    "        #2 BH 6\n",
    "        ( \"traces/1bh-6\", 'grid9_1bh-6_2019-02-13_12:59_',\"BH\"),\n",
    "        ( \"traces/1bh-6\", 'grid9_1bh-6_2019-02-13_19:15_',\"BH\"),\n",
    "        #2 BH 7\n",
    "         ( \"traces/1bh-7\", 'grid9_1bh-7_2019-02-13_15:08_',\"BH\"),\n",
    "         ( \"traces/1bh-7\", 'grid9_1bh-7_2019-02-13_20:02_',\"BH\"),\n",
    "         #2 bh 9\n",
    "         ( \"traces/1bh-9\", 'grid9_1bh-9_2019-02-13_15:57_',\"BH\"),\n",
    "         ( \"traces/1bh-9\", 'grid9_1bh-9_2019-02-13_19:35_',\"BH\"),\n",
    "         #3 normal\n",
    "         ( \"traces/normal\", 'grid9_normal_2019-02-13_17:05_',\"normal\"),\n",
    "         ( \"traces/normal\",  \"grid9_normal_2019-02-13_18:51_\",\"normal\"),\n",
    "         ( \"traces/normal\",  \"grid9_normal_2019-02-13_22:23_\",\"normal\"),\n",
    "        ]\n",
    "\n",
    "d= {\n",
    "    \"directory\":[],\n",
    "    \"case\":[],\n",
    "    \"case_accuracy\":[]\n",
    "}\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for i in plots:\n",
    "#     d[\"directory\"].append(i[0])\n",
    "#     d[\"case\"].append(i[1])\n",
    "#     d[\"case_accuracy\"].append(i[2])\n",
    "# df=pd.DataFrame(d)\n",
    "# df.to_csv(\"traces.csv\", sep='', encoding='utf-8')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['grid9_1bh-3_2019-02-13_16:28_ciao' 'grid9_1bh-3_2019-02-13_22:05_ciao'\n",
      " 'grid9_1bh-5_2019-02-13_15:31_ciao' 'grid9_1bh-5_2019-02-13_21:44_ciao'\n",
      " 'grid9_1bh-6_2019-02-13_12:59_ciao' 'grid9_1bh-6_2019-02-13_19:15_ciao'\n",
      " 'grid9_1bh-7_2019-02-13_15:08_ciao' 'grid9_1bh-7_2019-02-13_20:02_ciao'\n",
      " 'grid9_1bh-9_2019-02-13_15:57_ciao' 'grid9_1bh-9_2019-02-13_19:35_ciao'\n",
      " 'grid9_normal_2019-02-13_17:05_ciao' 'grid9_normal_2019-02-13_18:51_ciao'\n",
      " 'grid9_normal_2019-02-13_22:23_ciao' 'rnd_1bh-2_2019-02-14_15:38_ciao'\n",
      " 'rnd_1bh-7_2019-02-14_13:57_ciao' 'rnd_1bh-9_2019-02-14_15:15_ciao'\n",
      " 'rnd_normal_2019-02-14_13:37_ciao']\n"
     ]
    }
   ],
   "source": [
    "directory='../cooja3-9nodes/traces/traces.csv'\n",
    "df=pd.read_csv(directory, sep=',', encoding='utf-8')\n",
    "df\n",
    "col=df[\"case\"].values\n",
    "print(col)\n",
    "#for i in range(len(df)):\n",
    "    #print(i)\n",
    "    #print(df)\n",
    "    #col=df[\"cases\"]\n",
    "\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def analyze_network(directory,df,pings,window):\n",
    "    cases=[]\n",
    "    casesAccuracy=[]\n",
    "#     for row in plots:\n",
    "#         cases.append(row[1])\n",
    "#         casesAccuracy.append(row[2])\n",
    "#         data=import_Cooja2(plots)\n",
    "    cases=df[\"case\"].values\n",
    "    folder=df[\"directory\"].values+directory\n",
    "    \n",
    "    data=import_Cooja2(df)\n",
    "    \n",
    "    #pings=getPings(data)\n",
    "    #All data collection is in variable node that is a list of list of nodes\n",
    "    #3 nets input x 9 nodes by net\n",
    "    print(\"Processing...\")\n",
    "    d={ \"label\":[],\n",
    "       \"type\":[],\n",
    "        \"count\":[],\n",
    "        \"std\":  [],\n",
    "        \"mean\": [],\n",
    "        \"var\":  [],\n",
    "        \"hop\":[],\n",
    "\n",
    "       \"packet loss\":[],\n",
    "       \"outliers\":[],\n",
    "       \"node\":[]\n",
    "    }\n",
    "    #count=[]\n",
    "    labels=[]\n",
    "    var=[]\n",
    "    #window=100\n",
    "    #stats=pd.DataFrame(columns=columns)\n",
    "    n=pings\n",
    "\n",
    "    for i in range(len(data)):\n",
    "        #window=pings[i]\n",
    "\n",
    "        for j in range(len(data[i])):\n",
    "            #n=pings[i]\n",
    "\n",
    "            #print(n)\n",
    "            for z in range(0,n,int(window)):\n",
    "                #if(z+window>n):break\n",
    "                #print(z,z+window)\n",
    "\n",
    "                #df1 = df1.assign(e=p.Series(np.random.randn(sLength)).values)\n",
    "                node=data[i][j].pkts\n",
    "                name=str(j)+\" \"+cases[i]\n",
    "                nodeWindow=node[(node[\"seq\"]<z+window) & (node[\"seq\"]>=z)]\n",
    "                nodeWindowP=nodeWindow[\"rtt\"]\n",
    "                d[\"count\"].append(nodeWindowP.count())\n",
    "                #Case without outliers\n",
    "                #Case with outliers\n",
    "                std=0\n",
    "                if (nodeWindowP.std()>10):\n",
    "                    std=1\n",
    "                    std=nodeWindowP.std()\n",
    "\n",
    "                d[\"std\"].append(std)\n",
    "                mean=nodeWindowP.mean()\n",
    "                #if(mean<1):print(mean)\n",
    "                d[\"mean\"].append(mean)\n",
    "                var=0\n",
    "                if (nodeWindowP.var()>var): var=nodeWindowP.var()\n",
    "                d[\"var\"].append(var)\n",
    "                d[\"label\"].append(cases[i])\n",
    "                d[\"hop\"].append(data[i][j].hop)\n",
    "                d[\"type\"].append(casesAccuracy[i])\n",
    "                d[\"outliers\"].append(getOutliers(nodeWindow)[\"rtt\"].count())\n",
    "                missing=window-nodeWindow.count()\n",
    "                d[\"node\"].append(data[i][j].ip)\n",
    "                mP=getPercentageMissingPackets(nodeWindow,window)\n",
    "                PL=0\n",
    "                if(mP>30):\n",
    "                    PL=1\n",
    "                    PL=mP\n",
    "                d[\"packet loss\"].append(mP)\n",
    "\n",
    "\n",
    "\n",
    "    stats=pd.DataFrame(d)\n",
    "\n",
    "    dataK=stats.drop([\n",
    "        \"label\",\n",
    "        \"mean\",\n",
    "        \"var\",\n",
    "        \"std\",\n",
    "        #\"packet loss\",\n",
    "        \"outliers\",\n",
    "        \"hop\",\n",
    "        \"count\",\n",
    "        \"node\",\n",
    "        #\"type\"\n",
    "    ],axis=1)\n",
    "    dataK=dataK.fillna(0)\n",
    "\n",
    "    #print(dataK)\n",
    "    correction=[]\n",
    "    correction_alt=[]\n",
    "    col=np.array(dataK[\"type\"])\n",
    "    dataK=dataK.drop([\"type\"],axis=1)\n",
    "    #Creating simple array to correct unsupervised learning\n",
    "    #NB as it is unsupervised could happen that the correction are inverted\n",
    "    for i in range(len(col)):\n",
    "        el=d[\"type\"][i]\n",
    "        if el==\"normal\":\n",
    "            correction.append(1)\n",
    "            correction_alt.append(0)\n",
    "\n",
    "        else:\n",
    "\n",
    "            correction.append(0)\n",
    "            correction_alt.append(1)\n",
    "\n",
    "\n",
    "    dataC=stats[\"label\"]\n",
    "    kmeans = KMeans(n_clusters=2)\n",
    "    kmeans.fit(dataK)\n",
    "    labels = kmeans.predict(dataK)\n",
    "    centroids = kmeans.cluster_centers_\n",
    "    labels=accuracy_score_corrected(correction,labels)\n",
    "    predicted=[]\n",
    "    for i in range(len(labels)):\n",
    "\n",
    "        if(labels[i]==1):\n",
    "            predicted.append(\"normal\")\n",
    "        else: predicted.append(\"BH\")\n",
    "\n",
    "    #print(len(predicted))\n",
    "    stats[\"predicted\"]=pd.Series(np.array(predicted))\n",
    "    stats[\"predicted number\"]=pd.Series(np.array(labels))\n",
    "    stats[\"correction number\"]=pd.Series(np.array(correction))\n",
    "    stats_csv=stats[[\n",
    "        \"label\",\n",
    "        \"type\",\n",
    "        \"predicted\",\n",
    "        \"packet loss\",\n",
    "        \"outliers\",\n",
    "        \"std\",\n",
    "        \"hop\",\n",
    "        \"node\",\n",
    "        \"mean\"\n",
    "\n",
    "\n",
    "          ]]\n",
    "    stats_csv.to_csv(\"results_kmeans.csv\", sep='\\t', encoding='utf-8')\n",
    "    stats.head()\n",
    "    net_results={\n",
    "       \"case\":[],\n",
    "        \"predicted\":[],\n",
    "        \"real\":[]\n",
    "    }\n",
    "    #print(stats[\"predicted number\"])\n",
    "    for case in range(len(cases)):\n",
    "        subset=stats[stats[\"label\"]==cases[case]]\n",
    "        mean_predicted=str(subset[\"predicted number\"].mean()*100)+\"% normal\"\n",
    "        net_results[\"case\"].append(cases[case])\n",
    "        net_results[\"predicted\"].append(mean_predicted)\n",
    "        net_results[\"real\"].append(casesAccuracy[case])\n",
    "\n",
    "\n",
    "\n",
    "    results=pd.DataFrame(net_results)\n",
    "    results.to_csv(\"results_network_kmeans.csv\", sep='\\t', encoding='utf-8')\n",
    "    print(results)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "analyze_network(directory,data,200,12)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
